Afin de compléter, améliorer ou influencer les descripteurs extraits des séquences vidéo (et/ou audio), le projet vidéosense prend le parti d'exploiter les méta-données textuelles attachées au séquences vidéo formant le corpus d'application. Pour prendre en compte ces méta-données textuelles, nous avons choisi d'utiliser des descripteurs originaux, de nature sémantique et indépendants des langues des méta-données. Ces descripteurs (les vecteurs conceptuels) sont des vecteurs de dimension fixée, chaque dimension représentant une composante sémantique (identifiable ou non, selon l'expérience abordée). Ces descripteurs sont donc de même nature que les descripteurs video/audio et seront donc intégrés au processus de classification au même titre que les autres descripteurs. Dans un premier temps nous évoquons quelques unes des possibilités existant dans l'état de l'art avant de nous focaliser sur les vecteurs conceptuels puis présentons quelques unes des expériences actuellement menées.